# Tokenizer

The tokenizer is a tool for breaking down strings into more consumable
components called tokens. This is a very simple tokenizer designed to be
flexible so that it can work with a variety of input files and strings.
